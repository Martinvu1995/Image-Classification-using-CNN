{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo build CNN\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(filters = 32, kernel_size = 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "\n",
    "# adding a third convolutional layer\n",
    "classifier.add(Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Reading and Preprocessing images\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                      shear_range = 0.2,\n",
    "                                        zoom_range = 0.2,\n",
    "                                        horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8011 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('training_set',\n",
    "                                                    target_size = (64, 64),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Training the CNN\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "                ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "251/251 [==============================] - 55s 206ms/step - loss: 0.6702 - accuracy: 0.5818 - val_loss: 0.6319 - val_accuracy: 0.6680\n",
      "Epoch 2/100\n",
      "251/251 [==============================] - 48s 190ms/step - loss: 0.6078 - accuracy: 0.6707 - val_loss: 0.5741 - val_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "251/251 [==============================] - 49s 194ms/step - loss: 0.5647 - accuracy: 0.7105 - val_loss: 0.5518 - val_accuracy: 0.7215\n",
      "Epoch 4/100\n",
      "251/251 [==============================] - 47s 188ms/step - loss: 0.5279 - accuracy: 0.7355 - val_loss: 0.5299 - val_accuracy: 0.7265\n",
      "Epoch 5/100\n",
      "251/251 [==============================] - 55s 220ms/step - loss: 0.4993 - accuracy: 0.7563 - val_loss: 0.4982 - val_accuracy: 0.7590\n",
      "Epoch 6/100\n",
      "251/251 [==============================] - 49s 195ms/step - loss: 0.4821 - accuracy: 0.7647 - val_loss: 0.4742 - val_accuracy: 0.7790\n",
      "Epoch 7/100\n",
      "251/251 [==============================] - 53s 212ms/step - loss: 0.4630 - accuracy: 0.7792 - val_loss: 0.4526 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "251/251 [==============================] - 46s 185ms/step - loss: 0.4497 - accuracy: 0.7904 - val_loss: 0.4816 - val_accuracy: 0.7670\n",
      "Epoch 9/100\n",
      "125/251 [=============>................] - ETA: 20s - loss: 0.4477 - accuracy: 0.7871"
     ]
    }
   ],
   "source": [
    "history = classifier.fit_generator(training_set,\n",
    "                                    epochs = 100,\n",
    "                                    validation_data = test_set,\n",
    "                                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "classifier.save('model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert png to jpg\n",
    "\n",
    "# from PIL import Image\n",
    "# import os\n",
    "# import glob\n",
    "\n",
    "# path = 'D:\\WORK&LEARN\\TRAN MINH VU\\LDS8_Deeplearning\\CNN_Classification_images/test_data/test_data/tigers'\n",
    "# for filename in glob.glob(os.path.join(path, '*.png')):\n",
    "#     im = Image.open(filename)\n",
    "#     rgb_im = im.convert('RGB')\n",
    "#     rgb_im.save('test_data/' + os.path.basename(filename).split('.')[0] + '.jpg')\n",
    "#     print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete png file\n",
    "\n",
    "# import os\n",
    "# import glob\n",
    "\n",
    "# path = 'D:\\WORK&LEARN\\TRAN MINH VU\\LDS8_Deeplearning\\CNN_Classification_images/test_data/test_data/lions'\n",
    "# for filename in glob.glob(os.path.join(path, '*.png')):\n",
    "#     os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def print_result(test_image):\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    print(test_image.shape)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    print(test_image.shape)\n",
    "\n",
    "    result = classifier.predict(test_image)\n",
    "    print(result)\n",
    "    # 0: cat , 1: dog\n",
    "    if result[0][0] >= 0.5:\n",
    "        prediction = 'cat'\n",
    "    else:\n",
    "        prediction = 'dog'\n",
    "    print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "(1, 64, 64, 3)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "[[0.]]\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('predict_images\\cat_or_dog_3.jpg', target_size = (64, 64))\n",
    "print_result(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VU_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ddb6913ab5e46b7b3e52225c7058d24703a04543225f24706ca8fe94822d673"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
